{"episode_reward": [-300.0, -384.0, -134.0, -124.0, -168.0], "mean_absolute_error": [NaN, NaN, NaN, NaN, NaN], "mean_q": [NaN, NaN, NaN, NaN, NaN], "nb_steps": [201, 486, 521, 546, 615], "nb_episode": [0, 1, 2, 3, 4], "loss": [NaN, NaN, NaN, NaN, NaN], "duration": [0.3619912089998252, 0.2874186729986832, 0.03723981300026935, 0.025512645001072087, 0.06708269899900188], "episode": [0, 1, 2, 3, 4], "nb_episode_steps": [201, 285, 35, 25, 69]}